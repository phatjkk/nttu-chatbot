{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxhKiXJ1gwi1",
        "outputId": "a7cf254c-5782-4c86-a536-fda4ee5f707c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (0.0.28.post3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xformers) (1.26.4)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from xformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->xformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->xformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->xformers) (3.0.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.10/dist-packages (1.23.3)\n",
            "Requirement already satisfied: qdrant-client in /usr/local/lib/python3.10/dist-packages (1.12.1)\n",
            "Requirement already satisfied: wikipedia in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: FastAPI in /usr/local/lib/python3.10/dist-packages (0.115.5)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (0.32.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.11.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.21)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.10.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (9.0.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from optimum) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum) (1.13.1)\n",
            "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.10/dist-packages (from optimum) (4.46.2)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.10/dist-packages (from optimum) (2.5.1+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from optimum) (24.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from optimum) (0.26.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from optimum) (3.1.0)\n",
            "Requirement already satisfied: grpcio>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.0)\n",
            "Requirement already satisfied: grpcio-tools>=1.41.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (1.68.0)\n",
            "Requirement already satisfied: httpx>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (0.27.2)\n",
            "Requirement already satisfied: portalocker<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.10.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.14 in /usr/local/lib/python3.10/dist-packages (from qdrant-client) (2.2.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from wikipedia) (4.12.3)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from FastAPI) (0.41.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from FastAPI) (4.12.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.17.2)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (5.29.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from grpcio-tools>=1.41.0->qdrant-client) (75.1.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (3.10)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.3.1)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.10/dist-packages (from httpx[http2]>=0.20.0->qdrant-client) (4.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (2024.9.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.8.0->optimum) (4.66.6)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11->optimum) (3.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.29->optimum) (0.20.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->wikipedia) (2.6)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->optimum) (10.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum) (0.70.16)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.20.0->httpx[http2]>=0.20.0->qdrant-client) (1.2.2)\n",
            "Requirement already satisfied: hyperframe<7,>=6.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (6.0.1)\n",
            "Requirement already satisfied: hpack<5,>=4.0 in /usr/local/lib/python3.10/dist-packages (from h2<5,>=3->httpx[http2]>=0.20.0->qdrant-client) (4.0.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain) (3.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11->optimum) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (2.10.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic) (4.12.2)\n",
            "Requirement already satisfied: vllm in /usr/local/lib/python3.10/dist-packages (0.6.4.post1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from vllm) (5.9.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from vllm) (4.66.6)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from vllm) (9.0.0)\n",
            "Requirement already satisfied: transformers>=4.45.2 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.46.2)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from vllm) (5.29.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from vllm) (3.11.2)\n",
            "Requirement already satisfied: openai>=1.45.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (1.54.4)\n",
            "Requirement already satisfied: uvicorn[standard] in /usr/local/lib/python3.10/dist-packages (from vllm) (0.32.1)\n",
            "Requirement already satisfied: pydantic>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.10.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from vllm) (10.4.0)\n",
            "Requirement already satisfied: prometheus-client>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.21.0)\n",
            "Requirement already satisfied: prometheus-fastapi-instrumentator>=7.0.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (7.0.0)\n",
            "Requirement already satisfied: tiktoken>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.7.0)\n",
            "Requirement already satisfied: lm-format-enforcer<0.11,>=0.10.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.9)\n",
            "Requirement already satisfied: outlines<0.1,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.46)\n",
            "Requirement already satisfied: typing-extensions>=4.10 in /usr/local/lib/python3.10/dist-packages (from vllm) (4.12.2)\n",
            "Requirement already satisfied: filelock>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from vllm) (3.16.1)\n",
            "Requirement already satisfied: partial-json-parser in /usr/local/lib/python3.10/dist-packages (from vllm) (0.2.1.1.post4)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.10/dist-packages (from vllm) (24.0.1)\n",
            "Requirement already satisfied: msgspec in /usr/local/lib/python3.10/dist-packages (from vllm) (0.18.6)\n",
            "Requirement already satisfied: gguf==0.10.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.10.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from vllm) (8.5.0)\n",
            "Requirement already satisfied: mistral-common>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.5.0->vllm) (1.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from vllm) (6.0.2)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n",
            "Requirement already satisfied: compressed-tensors==0.8.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.8.0)\n",
            "Requirement already satisfied: ray>=2.9 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.39.0)\n",
            "Requirement already satisfied: nvidia-ml-py>=12.560.30 in /usr/local/lib/python3.10/dist-packages (from vllm) (12.560.30)\n",
            "Requirement already satisfied: torch==2.5.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision==0.20.1 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.20.1+cu121)\n",
            "Requirement already satisfied: xformers==0.0.28.post3 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.0.28.post3)\n",
            "Requirement already satisfied: fastapi!=0.113.*,!=0.114.0,>=0.107.0 in /usr/local/lib/python3.10/dist-packages (from vllm) (0.115.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1->vllm) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch==2.5.1->vllm) (1.3.0)\n",
            "Requirement already satisfied: starlette<0.42.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from fastapi!=0.113.*,!=0.114.0,>=0.107.0->vllm) (0.41.3)\n",
            "Requirement already satisfied: interegular>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (0.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lm-format-enforcer<0.11,>=0.10.9->vllm) (24.2)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.21.1 in /usr/local/lib/python3.10/dist-packages (from mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm) (4.23.0)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mistral-common[opencv]>=1.5.0->vllm) (4.10.0.84)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (0.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.45.0->vllm) (1.3.1)\n",
            "Requirement already satisfied: lark in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.2.2)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (1.6.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n",
            "Requirement already satisfied: diskcache in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (5.6.3)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.60.0)\n",
            "Requirement already satisfied: referencing in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (0.35.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (3.1.0)\n",
            "Requirement already satisfied: pycountry in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (24.6.1)\n",
            "Requirement already satisfied: pyairports in /usr/local/lib/python3.10/dist-packages (from outlines<0.1,>=0.0.43->vllm) (2.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.9->vllm) (2.27.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (8.1.7)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.1.0)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray>=2.9->vllm) (1.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->vllm) (2024.8.30)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.6.0->vllm) (2024.9.11)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.19.1->vllm) (0.26.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.45.2->vllm) (0.4.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (2.4.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (24.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->vllm) (4.0.3)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->vllm) (3.21.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.6.4)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (1.0.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]->vllm) (14.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=1.45.0->vllm) (1.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai>=1.45.0->vllm) (1.0.7)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm) (2024.10.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.21.1->mistral-common>=1.5.0->mistral-common[opencv]>=1.5.0->vllm) (0.21.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets->outlines<0.1,>=0.0.43->vllm) (0.70.16)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.5.1->vllm) (3.0.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->outlines<0.1,>=0.0.43->vllm) (0.43.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->outlines<0.1,>=0.0.43->vllm) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->outlines<0.1,>=0.0.43->vllm) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# Cài đặt xformers - thư viện tối ưu hóa transformer cho CUDA 12.1\n",
        "!pip install -U xformers --index-url https://download.pytorch.org/whl/cu121\n",
        "\n",
        "# Cài đặt các thư viện cần thiết:\n",
        "# - langchain: framework xử lý ngôn ngữ tự nhiên\n",
        "# - optimum: tối ưu hóa mô hình hugging face\n",
        "# - qdrant-client: kết nối với vector database Qdrant\n",
        "# - wikipedia: truy xuất dữ liệu từ Wikipedia\n",
        "# - FastAPI: framework API\n",
        "# - uvicorn: ASGI server\n",
        "# - pyngrok: tạo tunnel để expose API ra internet\n",
        "!pip install langchain optimum qdrant-client wikipedia FastAPI uvicorn pyngrok\n",
        "\n",
        "# Nâng cấp pydantic - thư viện validate data\n",
        "!pip install --upgrade pydantic\n",
        "\n",
        "# Cài đặt vllm - thư viện tối ưu hóa inference cho LLM\n",
        "!pip install vllm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3HW5GZanftjT"
      },
      "outputs": [],
      "source": [
        "#GENERATE_MODEL_NAME=\"phatjk/vietcuna-7b-v3-AWQ\"\n",
        "GENERATE_MODEL_NAME=\"vilm/vietcuna-3b-v2\"\n",
        "EMBEDDINGS_MODEL_NAME=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\"\n",
        "QDRANT_URL = \"https://d3966086-8c65-4b03-895a-6926e1f83994.us-east4-0.gcp.cloud.qdrant.io\"\n",
        "QDRANT_COLLECTION_NAME = \"Luat_vectordb\"\n",
        "QDRANT_COLLECTION_NAME = \"trung_luat_DB\"\n",
        "NGROK_STATIC_DOMAIN = \"briefly-knowing-treefrog.ngrok-free.app\"\n",
        "NGROK_TOKEN=          \"2pHsZScewzWnFPxgNOvwnCtfA9R_2J42SPU3YQJhacrYbj4hM\"\n",
        "HUGGINGFACE_API_KEY = \"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\"\n",
        "HUGGINGFACE_API_KEY = \"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\"\n",
        "QDRANT_API_KEY =      \"vkZ3snjz8mkKNj0weWgZxCvnz83ANbesUvYhz7HitC2X-rw_-d4hEg\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2lxJrOPoLEH",
        "outputId": "74b270f7-f4a3-4f5f-f282-f59986f745cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Import các thư viện cần thiết\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification  # Thư viện để load mô hình và tokenizer\n",
        "from optimum.bettertransformer import BetterTransformer  # Thư viện tối ưu hóa transformer\n",
        "import torch  # Framework deep learning PyTorch\n",
        "\n",
        "# Kiểm tra và sử dụng GPU nếu có, nếu không thì dùng CPU\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Load mô hình BERT đa ngôn ngữ được huấn luyện trên tập dữ liệu MS MARCO để xếp hạng lại các đoạn văn bản\n",
        "# Mô hình này sẽ cho điểm các đoạn văn bản dựa trên độ liên quan với câu truy vấn\n",
        "model_rerank = AutoModelForSequenceClassification.from_pretrained('amberoad/bert-multilingual-passage-reranking-msmarco').to(device)\n",
        "\n",
        "# Có thể bỏ comment dòng dưới để sử dụng BetterTransformer tối ưu hóa mô hình\n",
        "#model_rerank = BetterTransformer.transform(model_rerank)\n",
        "\n",
        "# Load tokenizer tương ứng với mô hình BERT đa ngôn ngữ\n",
        "# Tokenizer này sẽ chuyển đổi văn bản thành các token số để đưa vào mô hình\n",
        "tokenizer_rerank = AutoTokenizer.from_pretrained('amberoad/bert-multilingual-passage-reranking-msmarco')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MonGO3xSz23",
        "outputId": "90a5dfaa-b928-4ba1-c8ef-57bf4e69adce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.3.8)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<2.0.36,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.11.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: langchain<0.4.0,>=0.3.8 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.9)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.21 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.3.21)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.143)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.23.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain<0.4.0,>=0.3.8->langchain-community) (2.10.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.21->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.11)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<2.0.36,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.21->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.8->langchain-community) (2.27.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IFrBvSkL08Xn"
      },
      "outputs": [],
      "source": [
        "# from langchain.schema.document import Document\n",
        "# from langchain_core.vectorstores import VectorStoreRetriever\n",
        "# from langchain.retrievers import WikipediaRetriever\n",
        "# from typing import List\n",
        "# class RerankRetriever(VectorStoreRetriever):\n",
        "#     vectorstore: VectorStoreRetriever\n",
        "#     def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "#         docs = self.vectorstore.get_relevant_documents(query=query)\n",
        "#         candidates = [doc.page_content for doc in docs]\n",
        "#         queries = [query]*len(candidates)\n",
        "#         features = tokenizer_rerank(queries, candidates,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "#         with torch.no_grad():\n",
        "#             scores = model_rerank(**features).logits\n",
        "#             values, indices = torch.sum(scores, dim=1).sort()\n",
        "#             # relevant_docs = docs[indices[0]]\n",
        "#         return [docs[indices[0]],docs[indices[1]]]\n",
        "# class RerankWikiRetriever(VectorStoreRetriever):\n",
        "#     vectorstore: WikipediaRetriever\n",
        "#     def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "#         docs = self.vectorstore.get_relevant_documents(query=query)\n",
        "#         candidates = [doc.page_content for doc in docs]\n",
        "#         queries = [query]*len(candidates)\n",
        "#         features = tokenizer_rerank(queries, candidates,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "#         with torch.no_grad():\n",
        "#             scores = model_rerank(**features).logits\n",
        "#             values, indices = torch.sum(scores, dim=1).sort()\n",
        "#             # relevant_docs = docs[indices[0]]\n",
        "#         return [docs[indices[0]],docs[indices[1]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GHmTrDMTx1kP"
      },
      "outputs": [],
      "source": [
        "# from langchain.schema.document import Document\n",
        "# from langchain_core.vectorstores import VectorStoreRetriever\n",
        "# from langchain.retrievers import WikipediaRetriever\n",
        "# from typing import List\n",
        "\n",
        "# class RerankRetriever(VectorStoreRetriever):\n",
        "#     vectorstore: VectorStoreRetriever\n",
        "\n",
        "#     @property\n",
        "#     def embeddings(self):\n",
        "#         # Kiểm tra xem vectorstore có thuộc tính embeddings không\n",
        "#         if hasattr(self.vectorstore, 'embeddings'):\n",
        "#             return self.vectorstore.embeddings\n",
        "#         else:\n",
        "#             raise AttributeError(\"VectorStoreRetriever does not have 'embeddings' attribute.\")\n",
        "\n",
        "#     def _get_relevant_documents(self, query: str) -> List[Document]:  # Thay đổi ở đây\n",
        "#         docs = self.vectorstore.get_relevant_documents(query=query)\n",
        "#         candidates = [doc.page_content for doc in docs]\n",
        "#         queries = [query] * len(candidates)\n",
        "#         features = tokenizer_rerank(queries, candidates, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "#         with torch.no_grad():\n",
        "#             scores = model_rerank(**features).logits\n",
        "#             values, indices = torch.sum(scores, dim=1).sort()\n",
        "#         return [docs[indices[0]], docs[indices[1]]]\n",
        "\n",
        "# class RerankWikiRetriever(VectorStoreRetriever):\n",
        "#     vectorstore: WikipediaRetriever\n",
        "\n",
        "#     def _get_relevant_documents(self, query: str) -> List[Document]:  # Thay đổi ở đây\n",
        "#         docs = self.vectorstore.get_relevant_documents(query=query)\n",
        "#         candidates = [doc.page_content for doc in docs]\n",
        "#         queries = [query] * len(candidates)\n",
        "#         features = tokenizer_rerank(queries, candidates, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
        "#         with torch.no_grad():\n",
        "#             scores = model_rerank(**features).logits\n",
        "#             values, indices = torch.sum(scores, dim=1).sort()\n",
        "#         return [docs[indices[0]], docs[indices[1]]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ggkvUmN3HNyG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import các thư viện cần thiết\n",
        "from langchain.schema.document import Document  # Để làm việc với Document\n",
        "from langchain_core.vectorstores import VectorStoreRetriever  # Retriever cơ bản từ vector store\n",
        "from langchain.retrievers import WikipediaRetriever  # Retriever cho Wikipedia\n",
        "from typing import List  # Kiểu List cho type hinting\n",
        "\n",
        "class RerankRetriever:\n",
        "    \"\"\"\n",
        "    Custom retriever để rerank lại các documents từ một base retriever\n",
        "    \n",
        "    Attributes:\n",
        "        base_retriever: Retriever cơ bản để lấy documents ban đầu\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_retriever):\n",
        "        \"\"\"\n",
        "        Khởi tạo RerankRetriever với một base retriever\n",
        "        \n",
        "        Args:\n",
        "            base_retriever: Retriever cơ bản để lấy documents ban đầu\n",
        "        \"\"\"\n",
        "        self.base_retriever = base_retriever\n",
        "\n",
        "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Lấy documents từ base retriever và rerank lại chúng\n",
        "        \n",
        "        Args:\n",
        "            query: Câu truy vấn cần tìm documents\n",
        "            \n",
        "        Returns:\n",
        "            List[Document]: Danh sách 2 documents có điểm số cao nhất sau khi rerank\n",
        "        \"\"\"\n",
        "        # Lấy documents ban đầu từ base retriever\n",
        "        docs = self.base_retriever.get_relevant_documents(query=query)\n",
        "\n",
        "        # Chuẩn bị dữ liệu cho việc rerank\n",
        "        candidates = [doc.page_content for doc in docs]  # Nội dung của các documents\n",
        "        queries = [query] * len(candidates)  # Nhân bản query cho mỗi document\n",
        "\n",
        "        # Tokenize và chuyển dữ liệu sang tensor để rerank\n",
        "        features = tokenizer_rerank(\n",
        "            queries,\n",
        "            candidates,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        # Thực hiện rerank và lấy kết quả\n",
        "        with torch.no_grad():\n",
        "            scores = model_rerank(**features).logits  # Tính điểm cho mỗi document\n",
        "            values, indices = torch.sum(scores, dim=1).sort(descending=True)  # Sắp xếp giảm dần theo điểm\n",
        "\n",
        "        # Trả về 2 documents có điểm cao nhất\n",
        "        return [docs[indices[0]], docs[indices[1]]]\n",
        "\n",
        "def create_retriever(base_retriever):\n",
        "    \"\"\"\n",
        "    Hàm tiện ích để tạo rerank retriever\n",
        "    \n",
        "    Args:\n",
        "        base_retriever: Retriever cơ bản cần rerank\n",
        "        \n",
        "    Returns:\n",
        "        RerankRetriever: Một instance của RerankRetriever\n",
        "    \"\"\"\n",
        "    return RerankRetriever(base_retriever)\n",
        "\n",
        "# Ví dụ cách sử dụng:\n",
        "# wiki_retriever = WikipediaRetriever()  # Tạo Wikipedia retriever\n",
        "# rerank_retriever = create_retriever(wiki_retriever)  # Tạo rerank retriever từ Wikipedia retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRMPAAYpRcMJ",
        "outputId": "68dc9191-d43a-4ab7-da47-85b50284bdd5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.44.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.26.2)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RAG PIPELINE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "RAG (Retrieval-Augmented Generation) là một phương pháp kết hợp giữa việc truy xuất tài liệu và sinh văn bản, nhằm cải thiện khả năng trả lời câu hỏi dựa trên ngữ cảnh. RAG pipeline cho phép hệ thống truy xuất thông tin từ các nguồn dữ liệu bên ngoài (như cơ sở dữ liệu hoặc Wikipedia) và sử dụng thông tin đó để sinh ra câu trả lời chính xác và liên quan hơn cho người dùng."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Các Thành Phần Chính Của RAG Pipeline:\n",
        "- **Retriever**: Thành phần này chịu trách nhiệm lấy các tài liệu liên quan từ nguồn dữ liệu dựa trên truy vấn của người dùng. Nó có thể là một retriever cơ bản như WikipediaRetriever hoặc một retriever từ cơ sở dữ liệu như Qdrant.\n",
        "- **Mô Hình Ngôn Ngữ**: Sử dụng các mô hình ngôn ngữ tiên tiến (như VLLM) để sinh ra câu trả lời dựa trên các tài liệu đã được truy xuất.\n",
        "- **Template Prompt**: Định nghĩa cách thức mà chatbot sẽ trả lời câu hỏi dựa trên ngữ cảnh và câu hỏi của người dùng.\n",
        "- **Pipeline RAG**: Kết hợp tất cả các thành phần lại với nhau để tạo thành một quy trình hoàn chỉnh cho việc truy vấn và sinh văn bản.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Sơ Lược Các Hàm Trong Code\n",
        "\n",
        "Lớp `LLMServe`\n",
        "\n",
        "- **`__init__(self)`**: \n",
        "  - Khởi tạo các thành phần của RAG pipeline, bao gồm tải embeddings, xác định nguồn dữ liệu, tải retriever, tải mô hình ngôn ngữ, tạo template cho prompt, và tạo RAG pipeline hoàn chỉnh.\n",
        "\n",
        "- **`load_embeddings(self)`**:\n",
        "  - Tải mô hình embeddings từ HuggingFace để chuyển đổi văn bản thành vector.\n",
        "\n",
        "- **`load_retriever(self, retriever_name, embeddings)`**:\n",
        "  - Tải và tạo retriever phù hợp dựa trên tên nguồn dữ liệu (Wikipedia hoặc Qdrant).\n",
        "  - Nếu là Wikipedia, sử dụng `WikipediaRetriever`.\n",
        "  - Nếu là Qdrant, kết nối với QdrantClient và tạo retriever từ cơ sở dữ liệu.\n",
        "\n",
        "- **`load_model_pipeline(self, max_new_tokens=100)`**:\n",
        "  - Tải mô hình ngôn ngữ chính (VLLM) với các tham số như số lượng token tối đa, top-k, top-p, và nhiệt độ.\n",
        "\n",
        "- **`load_prompt_template(self)`**:\n",
        "  - Tạo template cho prompt mà chatbot sẽ sử dụng để trả lời câu hỏi dựa trên ngữ cảnh.\n",
        "\n",
        "- **`load_rag_pipeline(self, llm, retriever, prompt)`**:\n",
        "  - Tạo RAG pipeline hoàn chỉnh bằng cách kết hợp mô hình ngôn ngữ, retriever và prompt.\n",
        "  - Sử dụng `RetrievalQA.from_chain_type` để tạo ra một pipeline cho việc truy vấn và trả về tài liệu nguồn.\n",
        "\n",
        "- **`rag(self, source)`**:\n",
        "  - Phương thức này cho phép lấy hoặc tạo mới RAG pipeline dựa trên nguồn dữ liệu được chỉ định.\n",
        "  - Nếu nguồn dữ liệu không thay đổi, trả về pipeline hiện tại; nếu có thay đổi, tải lại retriever và tạo pipeline mới.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjHRgM79Pr-c",
        "outputId": "9bd14f3a-7d26-4cd7-dd5a-90863b86d13c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-8d76f52a1e39>:36: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
            "  class RerankRetriever(BaseRetriever):\n",
            "<ipython-input-9-8d76f52a1e39>:36: DeprecationWarning: Retrievers must implement abstract `_aget_relevant_documents` method instead of `aget_relevant_documents`\n",
            "  class RerankRetriever(BaseRetriever):\n"
          ]
        }
      ],
      "source": [
        "# Import các thư viện cần thiết\n",
        "from langchain.schema.document import Document\n",
        "from langchain.schema.retriever import BaseRetriever\n",
        "from langchain.retrievers import WikipediaRetriever\n",
        "from langchain.vectorstores import Qdrant\n",
        "from langchain.llms import HuggingFacePipeline, VLLM, HuggingFaceHub\n",
        "from qdrant_client import QdrantClient\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "from langchain.chains import RetrievalQA, MultiRetrievalQAChain\n",
        "from typing import List\n",
        "import asyncio\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class RerankRetriever(BaseRetriever):\n",
        "    \"\"\"\n",
        "    Custom retriever thực hiện việc rerank các documents từ một base retriever\n",
        "    \n",
        "    Attributes:\n",
        "        base_retriever: Retriever cơ bản để lấy documents ban đầu\n",
        "    \"\"\"\n",
        "\n",
        "    base_retriever: BaseRetriever = Field(description=\"Base retriever to get initial documents\")\n",
        "\n",
        "    model_config = {\n",
        "        \"arbitrary_types_allowed\": True,\n",
        "        \"extra\": \"allow\"\n",
        "    }\n",
        "\n",
        "    def __init__(self, base_retriever: BaseRetriever):\n",
        "        super().__init__(base_retriever=base_retriever)\n",
        "\n",
        "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Lấy documents từ base retriever và rerank chúng\n",
        "        \n",
        "        Args:\n",
        "            query: Câu truy vấn cần tìm documents liên quan\n",
        "            \n",
        "        Returns:\n",
        "            List[Document]: Danh sách 2 documents có điểm số cao nhất sau khi rerank\n",
        "        \"\"\"\n",
        "        docs = self.base_retriever.get_relevant_documents(query=query)\n",
        "\n",
        "        candidates = [doc.page_content for doc in docs]\n",
        "        queries = [query] * len(candidates)\n",
        "\n",
        "        features = tokenizer_rerank(\n",
        "            queries,\n",
        "            candidates,\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            scores = model_rerank(**features).logits\n",
        "            values, indices = torch.sum(scores, dim=1).sort(descending=True)\n",
        "\n",
        "        return [docs[indices[0]], docs[indices[1]]]\n",
        "\n",
        "    async def aget_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"\n",
        "        Phiên bản bất đồng bộ của get_relevant_documents\n",
        "        \n",
        "        Args:\n",
        "            query: Câu truy vấn cần tìm documents liên quan\n",
        "            \n",
        "        Returns:\n",
        "            List[Document]: Danh sách documents liên quan\n",
        "        \"\"\"\n",
        "        return await asyncio.to_thread(self.get_relevant_documents, query)\n",
        "\n",
        "\n",
        "class LLMServe:\n",
        "    \"\"\"\n",
        "    Class chính để phục vụ mô hình ngôn ngữ với RAG pipeline\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Khởi tạo các thành phần của RAG pipeline\"\"\"\n",
        "        self.embeddings = self.load_embeddings()\n",
        "        self.current_source = \"wiki\"\n",
        "        self.retriever = self.load_retriever(retriever_name=self.current_source, embeddings=self.embeddings)\n",
        "        self.pipe = self.load_model_pipeline(max_new_tokens=300)\n",
        "        self.prompt = self.load_prompt_template()\n",
        "        self.rag_pipeline = self.load_rag_pipeline(llm=self.pipe,\n",
        "                                                 retriever=self.retriever,\n",
        "                                                 prompt=self.prompt)\n",
        "\n",
        "    def load_embeddings(self):\n",
        "        \"\"\"Tải mô hình embeddings từ HuggingFace\"\"\"\n",
        "        embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
        "            model_name=EMBEDDINGS_MODEL_NAME,\n",
        "            api_key=HUGGINGFACE_API_KEY,\n",
        "        )\n",
        "        return embeddings\n",
        "\n",
        "    def load_retriever(self, retriever_name, embeddings):\n",
        "        \"\"\"\n",
        "        Tải và tạo retriever phù hợp dựa trên tên\n",
        "        \n",
        "        Args:\n",
        "            retriever_name: Tên loại retriever (\"wiki\" hoặc khác)\n",
        "            embeddings: Mô hình embeddings đã tải\n",
        "            \n",
        "        Returns:\n",
        "            RerankRetriever: Retriever đã được cấu hình\n",
        "        \"\"\"\n",
        "        if retriever_name == \"wiki\":\n",
        "            base_retriever = WikipediaRetriever(\n",
        "                lang=\"vi\",\n",
        "                doc_content_chars_max=800,\n",
        "                top_k_results=15\n",
        "            )\n",
        "            return RerankRetriever(base_retriever)\n",
        "        else:\n",
        "            client = QdrantClient(\n",
        "                url=QDRANT_URL,\n",
        "                api_key=QDRANT_API_KEY,\n",
        "                prefer_grpc=False\n",
        "            )\n",
        "\n",
        "            db = Qdrant(\n",
        "                client=client,\n",
        "                embeddings=embeddings,\n",
        "                collection_name=QDRANT_COLLECTION_NAME\n",
        "            )\n",
        "\n",
        "            base_retriever = db.as_retriever(search_kwargs={\"k\": 15})\n",
        "            return RerankRetriever(base_retriever)\n",
        "\n",
        "    def load_model_pipeline(self, max_new_tokens=100):\n",
        "        \"\"\"Tải mô hình ngôn ngữ chính\"\"\"\n",
        "        llm = VLLM(\n",
        "            model=GENERATE_MODEL_NAME,\n",
        "            trust_remote_code=True,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            top_k=10,\n",
        "            top_p=0.95,\n",
        "            temperature=0.4,\n",
        "            dtype=\"half\",\n",
        "        )\n",
        "        return llm\n",
        "\n",
        "    def load_prompt_template(self):\n",
        "        \"\"\"Tạo template cho prompt\"\"\"\n",
        "        query_template = \"Bạn là một chatbot thông minh trả lời câu hỏi dựa trên ngữ cảnh (context).\\n\\n### Context:{context} \\n\\n### Human: {question}\\n\\n### Assistant:\"\n",
        "        prompt = PromptTemplate(template=query_template,\n",
        "                              input_variables=[\"context\", \"question\"])\n",
        "        return prompt\n",
        "\n",
        "    def load_rag_pipeline(self, llm, retriever, prompt):\n",
        "        \"\"\"Tạo RAG pipeline hoàn chỉnh\"\"\"\n",
        "        rag_pipeline = RetrievalQA.from_chain_type(\n",
        "            llm=llm,\n",
        "            chain_type='stuff',\n",
        "            retriever=retriever,\n",
        "            chain_type_kwargs={\n",
        "                \"prompt\": prompt\n",
        "            },\n",
        "            return_source_documents=True)\n",
        "        return rag_pipeline\n",
        "\n",
        "    def rag(self, source):\n",
        "        \"\"\"\n",
        "        Lấy hoặc tạo mới RAG pipeline dựa trên nguồn\n",
        "        \n",
        "        Args:\n",
        "            source: Nguồn dữ liệu cần truy vấn\n",
        "            \n",
        "        Returns:\n",
        "            RetrievalQA: Pipeline RAG đã cấu hình\n",
        "        \"\"\"\n",
        "        if source == self.current_source:\n",
        "            return self.rag_pipeline\n",
        "        else:\n",
        "            self.retriever = self.load_retriever(retriever_name=source, embeddings=self.embeddings)\n",
        "            self.rag_pipeline = self.load_rag_pipeline(llm=self.pipe,\n",
        "                                                     retriever=self.retriever,\n",
        "                                                     prompt=self.prompt)\n",
        "            self.current_source = source\n",
        "            return self.rag_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmICGMPnNgKb",
        "outputId": "6f74158b-7063-4082-f338-63cc2df4e28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install triton"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340,
          "referenced_widgets": [
            "2c340060d6584cf385abe111e21e862e",
            "fa5fa77e38bf48049044f0a6ff8d8fe4",
            "819ad45e1b6e4c4a90a7d0da937df31f",
            "8e43c12757d34f95953cce24bc3f3290",
            "829c1b9b5d2e4dbc9a5abca314599002",
            "3b06f357194c4fc699956b868bf1d374",
            "79d84040ae8245578a5d3e8719610e7e",
            "db4d9fd4dfcb4eaa8c6dad909e9ae305",
            "ddf11837ebb941b1a3c9de221b225ef9",
            "0b3d790938334583b70b65de8fda3146",
            "30cffb5f9d1946a190c818227a412cf9"
          ]
        },
        "id": "TiTUoHEmQBOo",
        "outputId": "b772e186-e1e2-492b-92c8-28ed2243c299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING 11-28 13:08:36 config.py:1865] Casting torch.bfloat16 to torch.float16.\n",
            "INFO 11-28 13:08:56 llm_engine.py:249] Initializing an LLM engine (v0.6.4.post1) with config: model='vilm/vietcuna-3b-v2', speculative_config=None, tokenizer='vilm/vietcuna-3b-v2', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=LoadFormat.AUTO, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=vilm/vietcuna-3b-v2, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, chat_template_text_format=string, mm_processor_kwargs=None, pooler_config=None)\n",
            "INFO 11-28 13:09:00 selector.py:261] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
            "INFO 11-28 13:09:00 selector.py:144] Using XFormers backend.\n",
            "INFO 11-28 13:09:01 model_runner.py:1072] Starting to load model vilm/vietcuna-3b-v2...\n",
            "INFO 11-28 13:09:01 weight_utils.py:243] Using model weights format ['*.safetensors']\n",
            "INFO 11-28 13:09:02 weight_utils.py:288] No model.safetensors.index.json found in remote.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2c340060d6584cf385abe111e21e862e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO 11-28 13:09:32 model_runner.py:1077] Loading model weights took 5.6083 GB\n",
            "INFO 11-28 13:09:36 worker.py:232] Memory profiling results: total_gpu_memory=14.75GiB initial_memory_usage=6.43GiB peak_torch_memory=8.53GiB memory_usage_post_profile=6.46GiB non_torch_memory=0.22GiB kv_cache_size=4.52GiB gpu_memory_utilization=0.90\n",
            "INFO 11-28 13:09:36 gpu_executor.py:113] # GPU blocks: 988, # CPU blocks: 873\n",
            "INFO 11-28 13:09:36 gpu_executor.py:117] Maximum concurrency for 2048 tokens per request: 7.72x\n",
            "INFO 11-28 13:09:41 model_runner.py:1400] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
            "INFO 11-28 13:09:41 model_runner.py:1404] If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
            "INFO 11-28 13:10:15 model_runner.py:1518] Graph capturing finished in 34 secs, took 0.89 GiB\n"
          ]
        }
      ],
      "source": [
        "# Khởi tạo instance của LLMServe\n",
        "app = LLMServe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "doMVLeI1P-RO"
      },
      "outputs": [],
      "source": [
        "# from typing import Union\n",
        "# from fastapi.middleware.cors import CORSMiddleware\n",
        "# from fastapi.responses import JSONResponse\n",
        "# from fastapi.encoders import jsonable_encoder\n",
        "# from fastapi import FastAPI\n",
        "# origins = [\"*\"]\n",
        "# app_api = FastAPI()\n",
        "# app_api.add_middleware(\n",
        "#     CORSMiddleware,\n",
        "#     allow_origins=origins,\n",
        "#     allow_credentials=True,\n",
        "#     allow_methods=[\"*\"],\n",
        "#     allow_headers=[\"*\"],\n",
        "# )\n",
        "\n",
        "# @app_api.get(\"/\")\n",
        "# def read_root():\n",
        "#     return \"API RAG\"\n",
        "\n",
        "# @app_api.get(\"/rag/{source}\")\n",
        "# async def read_item(source: str, q: str | None = None):\n",
        "#     if q:\n",
        "#         data = app.rag(source=source)(q)\n",
        "#         sources = []\n",
        "#         for docs in data[\"source_documents\"]:\n",
        "#             sources.append(docs.to_json()[\"kwargs\"])\n",
        "#         res = {\n",
        "#             \"result\" : data[\"result\"],\n",
        "#             \"source_documents\":sources\n",
        "#         }\n",
        "#         return JSONResponse(content=jsonable_encoder(res))\n",
        "#     return None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mIb5IEgjn_5y"
      },
      "outputs": [],
      "source": [
        "# Import các thư viện cần thiết\n",
        "from typing import Union, Optional\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from fastapi.responses import JSONResponse \n",
        "from fastapi.encoders import jsonable_encoder\n",
        "from fastapi import FastAPI, HTTPException\n",
        "\n",
        "# Định nghĩa các nguồn dữ liệu hợp lệ cho hệ thống RAG\n",
        "VALID_SOURCES = [\"nttu\", \"wiki\"]\n",
        "\n",
        "# Cấu hình CORS cho phép truy cập từ các domain khác\n",
        "origins = [\"*\"]\n",
        "app_api = FastAPI()\n",
        "app_api.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"], # Cho phép tất cả các nguồn truy cập API\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"], # Cho phép tất cả các phương thức HTTP\n",
        "    allow_headers=[\"*\"], # Cho phép tất cả các header\n",
        ")\n",
        "\n",
        "# Endpoint kiểm tra API có hoạt động hay không\n",
        "@app_api.get(\"/\")\n",
        "def read_root():\n",
        "    \"\"\"\n",
        "    Endpoint mặc định trả về thông báo API đang chạy\n",
        "    Returns:\n",
        "        dict: Thông báo API đang hoạt động\n",
        "    \"\"\"\n",
        "    return {\"message\": \"API RAG is running\"}\n",
        "\n",
        "# Endpoint chính để xử lý truy vấn RAG\n",
        "@app_api.get(\"/rag/{source}\")\n",
        "async def read_item(source: str, q: Optional[str] = None):\n",
        "    \"\"\"\n",
        "    Endpoint xử lý truy vấn RAG với nguồn dữ liệu được chỉ định\n",
        "    \n",
        "    Args:\n",
        "        source (str): Nguồn dữ liệu (nttu hoặc wiki)\n",
        "        q (str, optional): Câu truy vấn từ người dùng\n",
        "    \n",
        "    Returns:\n",
        "        JSONResponse: Kết quả trả về bao gồm câu trả lời và tài liệu nguồn\n",
        "    \n",
        "    Raises:\n",
        "        HTTPException: Nếu nguồn dữ liệu không hợp lệ hoặc thiếu query\n",
        "    \"\"\"\n",
        "    # Kiểm tra nguồn dữ liệu có hợp lệ không\n",
        "    if source not in VALID_SOURCES:\n",
        "        raise HTTPException(\n",
        "            status_code=400,\n",
        "            detail=f\"Invalid source. Must be one of: {VALID_SOURCES}\"\n",
        "        )\n",
        "\n",
        "    # Kiểm tra có câu truy vấn hay không\n",
        "    if not q:\n",
        "        raise HTTPException(\n",
        "            status_code=400,\n",
        "            detail=\"Query parameter 'q' is required\"\n",
        "        )\n",
        "\n",
        "    try:\n",
        "        # In thông tin debug để theo dõi quá trình xử lý\n",
        "        print(f\"Debug - Processing request for source: {source}, query: {q}\")\n",
        "        rag_chain = app.rag(source=source)\n",
        "        print(f\"Debug - RAG chain type: {type(rag_chain)}\")\n",
        "        \n",
        "        # Thực hiện truy vấn RAG\n",
        "        data = rag_chain.invoke({\"query\": q})\n",
        "\n",
        "        # Xử lý và định dạng kết quả trả về\n",
        "        sources = []\n",
        "        for docs in data[\"source_documents\"]:\n",
        "            sources.append(docs.to_json()[\"kwargs\"])\n",
        "\n",
        "        return JSONResponse(content=jsonable_encoder({\n",
        "            \"result\": data[\"result\"],\n",
        "            \"source_documents\": sources\n",
        "        }))\n",
        "\n",
        "    except Exception as e:\n",
        "        # Xử lý và ghi log lỗi chi tiết\n",
        "        print(f\"Detailed error in endpoint: {str(e)}\")\n",
        "        print(f\"Error type: {type(e)}\")\n",
        "        import traceback\n",
        "        print(f\"Traceback: {traceback.format_exc()}\")\n",
        "        raise HTTPException(\n",
        "            status_code=500,\n",
        "            detail=f\"An error occurred: {str(e)}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nếu có người cùng IP mạng dùng ngrok => bug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukVRYqtA3tUa",
        "outputId": "c1291e78-e0cd-4036-c714-0bbc64b3d966"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ngrok - tunnel local ports to public URLs and inspect traffic\n",
            "\n",
            "USAGE:\n",
            "  ngrok [command] [flags]\n",
            "\n",
            "AUTHOR:\n",
            "  ngrok - <support@ngrok.com>\n",
            "\n",
            "COMMANDS: \n",
            "  config          update or migrate ngrok's configuration file\n",
            "  http            start an HTTP tunnel\n",
            "  tcp             start a TCP tunnel\n",
            "  tunnel          start a tunnel for use with a tunnel-group backend\n",
            "\n",
            "EXAMPLES: \n",
            "  ngrok http 80                                                 # secure public URL for port 80 web server\n",
            "  ngrok http --url baz.ngrok.dev 8080                           # port 8080 available at baz.ngrok.dev\n",
            "  ngrok tcp 22                                                  # tunnel arbitrary TCP traffic to port 22\n",
            "  ngrok http 80 --oauth=google --oauth-allow-email=foo@foo.com  # secure your app with oauth\n",
            "\n",
            "Paid Features: \n",
            "  ngrok http 80 --url mydomain.com                              # run ngrok with your own custom domain\n",
            "  ngrok http 80 --cidr-allow 2600:8c00::a03c:91ee:fe69:9695/32  # run ngrok with IP policy restrictions\n",
            "  Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Upgrade your account at https://dashboard.ngrok.com/billing/subscription to access paid features\n",
            "\n",
            "Flags:\n",
            "  -h, --help      help for ngrok\n",
            "\n",
            "Use \"ngrok [command] --help\" for more information about a command.\n"
          ]
        }
      ],
      "source": [
        "!ngrok kill\n",
        "!ngrok start --all\n",
        "\n",
        "# Nếu có người cùng IP mạng dùng ngrok => bug\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q37mk_ROF_NN",
        "outputId": "a72ede90-6c9d-41fd-cdf6-bbd881f6d2e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Public URL: https://briefly-knowing-treefrog.ngrok-free.app\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [4623]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     117.5.220.91:0 - \"OPTIONS /rag/nttu?q=lu%E1%BA%ADt%20%C4%91%C6%B0%E1%BB%9Dng%20b%E1%BB%99 HTTP/1.1\" 200 OK\n",
            "Debug - Processing request for source: nttu, query: luật đường bộ\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-8d76f52a1e39>:111: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
            "  db = Qdrant(\n",
            "<ipython-input-9-8d76f52a1e39>:51: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = self.base_retriever.get_relevant_documents(query=query)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Debug - RAG chain type: <class 'langchain.chains.retrieval_qa.base.RetrievalQA'>\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
            "Processed prompts: 100%|██████████| 1/1 [00:07<00:00,  7.42s/it, est. speed input: 52.07 toks/s, output: 30.21 toks/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:     117.5.220.91:0 - \"GET /rag/nttu?q=lu%E1%BA%ADt%20%C4%91%C6%B0%E1%BB%9Dng%20b%E1%BB%99 HTTP/1.1\" 200 OK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [4623]\n"
          ]
        }
      ],
      "source": [
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "\n",
        "# Kill any existing ngrok processes first\n",
        "ngrok.kill()\n",
        "\n",
        "# Set up new ngrok tunnel\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "ngrok_tunnel = ngrok.connect(8000, domain=NGROK_STATIC_DOMAIN)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "\n",
        "# Apply nest_asyncio to avoid runtime errors\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Run the server\n",
        "uvicorn.run(app_api, port=8000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dXthRmfbx-rZ"
      },
      "source": [
        "## fix bug - testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClCpdsTjzhNC",
        "outputId": "3943ca67-ec29-4f76-d5ba-57da9056dbcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection info: status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=0 points_count=65 segments_count=2 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=768, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None) payload_schema={}\n",
            "\n",
            "Point ID: 01ad046c-5cc4-4a52-8624-a1bdcc0602c2\n",
            "Payload: {'page_content': 'Điều 16. Lùi xe\\n1. Khi lùi xe, người điều khiển phải quan sát phía sau, có tín hiệu cần thiết và chỉ khi nào thấy không nguy hiểm mới được lùi.\\n2. Không được lùi xe ở khu vực cấm dừng, trên phần đường dành cho người đi bộ qua đường, nơi đường bộ giao nhau, đường bộ giao nhau cùng mức với đường sắt, nơi tầm nhìn bị che khuất, trong hầm đường bộ, đường cao tốc.\\nĐiều 17. Tránh xe đi ngược chiều\\n1. Trên đường không phân chia thành hai chiều xe chạy riêng biệt, hai xe đi ngược chiều tránh nhau, người điều khiển phải giảm tốc độ và cho xe đi về bên phải theo chiều xe chạy của mình.\\n2. Các trường hợp nhường đường khi tránh nhau quy định như sau:\\na) Nơi đường hẹp chỉ đủ cho một xe chạy và có chỗ tránh xe thì xe nào ở gần chỗ tránh hơn phải vào vị trí tránh, nhường đường cho xe kia đi;', 'metadata': {'source': 'D:/OneDrive - Hanoi University of Science and Technology/GIT/chatbot_vietcunaModel_QdantDB_Legal2008Text_ngrokTunneling/dataset/sotay.txt'}}\n",
            "\n",
            "Point ID: 044fb2ff-0f35-488a-978e-481be278f985\n",
            "Payload: {'page_content': 'đ) Không mở cửa xe, để cửa xe mở hoặc bước xuống xe khi chưa bảo đảm điều kiện an toàn;\\ne) Khi dừng xe, không được tắt máy và không được rời khỏi vị trí lái;\\ng) Xe đỗ trên đoạn đường dốc phải được chèn bánh.\\n4. Người điều khiển phương tiện không được dừng xe, đỗ xe tại các vị trí sau đây:\\na) Bên trái đường một chiều;\\nb) Trên các đoạn đường cong và gần đầu dốc tầm nhìn bị che khuất;\\nc) Trên cầu, gầm cầu vượt;\\nd) Song song với một xe khác đang dừng, đỗ;\\nđ) Trên phần đường dành cho người đi bộ qua đường;\\ne) Nơi đường giao nhau và trong phạm vi 5 mét tính từ mép đường giao nhau;\\ng) Nơi dừng của xe buýt;\\nh) Trước cổng và trong phạm vi 5 mét hai bên cổng trụ sở cơ quan, tổ chức;\\ni) Tại nơi phần đường có bề rộng chỉ đủ cho một làn xe;\\nk) Trong phạm vi an toàn của đường sắt;', 'metadata': {'source': 'D:/OneDrive - Hanoi University of Science and Technology/GIT/chatbot_vietcunaModel_QdantDB_Legal2008Text_ngrokTunneling/dataset/sotay.txt'}}\n"
          ]
        }
      ],
      "source": [
        "# from qdrant_client import QdrantClient\n",
        "\n",
        "# # Kết nối tới Qdrant\n",
        "# client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
        "\n",
        "# # Lấy thông tin collection\n",
        "# collection_info = client.get_collection(QDRANT_COLLECTION_NAME)\n",
        "# print(\"Collection info:\", collection_info)\n",
        "\n",
        "# # Lấy một số points để kiểm tra\n",
        "# points = client.scroll(\n",
        "#     collection_name=QDRANT_COLLECTION_NAME,\n",
        "#     limit=2  # Lấy 2 điểm đầu tiên\n",
        "# )\n",
        "# for point in points[0]:\n",
        "#     print(\"\\nPoint ID:\", point.id)\n",
        "#     print(\"Payload:\", point.payload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWLuEONCv_Nx",
        "outputId": "f3e20945-82d8-42bc-b725-f457aac3edde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collection info: status=<CollectionStatus.GREEN: 'green'> optimizer_status=<OptimizersStatusOneOf.OK: 'ok'> vectors_count=None indexed_vectors_count=0 points_count=209 segments_count=2 config=CollectionConfig(params=CollectionParams(vectors=VectorParams(size=768, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None) payload_schema={}\n",
            "\n",
            "Point ID: 0078183d-55d7-4fc7-8ebd-a64bcc4c54d6\n",
            "Payload: {'page_content': '+ Đối với sinh viên học liên thông đại học đã có bằng đại học (từ 2021) được xét miễn học/ chuyển điểm theo Quyết định số 411/QĐ-NTT ngày 06/4/2021.\\n+ Đối với sinh viên học liên thông đại học từ cao đẳng, trung cấp được xét miễn học/ chuyển điểm theo Quyết định số 139/QĐ-NTT ngày 04/02/2021.\\nQuy trình: Sinh viên tải mẫu đơn BM-ĐT-06 xin miễn học/ chuyển điểm điền đầy đủ thông tin trên đơn và nộp đơn tại Phòng Quản lý Đào tạo, đồng thời nộp kèm bản sao công chứng của bảng điểm, chứng chỉ, bằng tốt nghiệp của môn học xin miễn học/ chuyển điểm. Trong thời gian chờ duyệt kết quả chuyển điểm, sinh viên vẫn phải đi học đầy đủ, không được tự ý nghỉ học.\\nThời gian giải quyết: 07 ngày làm việc (trừ thứ 7, Chủ nhật, ngày lễ). Đối với học phần TOEIC, thời gian xét duyệt theo thông báo', 'metadata': {'source': 'sotay.txt'}}\n",
            "\n",
            "Point ID: 0245daa5-6868-42f6-ae4e-3f48bd85e9f2\n",
            "Payload: {'page_content': 'Tầm nhìn đến năm 2035, Trường Đại học Nguyễn Tất Thành trở thành đại học đổi mới sáng tạo, đa ngành, đa lĩnh vực có tính hội nhập cao, đào tạo nguồn nhân lực gắn với nhu cầu trong và ngoài nước, đáp ứng Cách mạng công nghiệp 4.0, đạt chuẩn khu vực và quốc tế.\\nVề sứ mạng, Trường Đại học Nguyễn Tất Thành cam kết tạo môi trường học tập với mục tiêu phát triển toàn diện con người để người học trở thành một công dân tích cực, có năng lực khởi nghiệp, đổi mới sáng tạo, hội nhập, có sức cạnh tranh cao trong thị trường lao động trong và ngoài nước thông qua hoạt động đào tạo, nghiên cứu ứng dụng, chuyển giao công nghệ, và phục vụ cộng đồng, xã hội dựa trên liên minh chiến lược gắn kết với các doanh nghiệp và các viện nghiên cứu.', 'metadata': {'source': 'D:/OneDrive - Hanoi University of Science and Technology/GIT/nttu-chatbot/dataset/sotay.txt'}}\n"
          ]
        }
      ],
      "source": [
        "# from qdrant_client import QdrantClient\n",
        "\n",
        "# # Kết nối tới Qdrant\n",
        "# client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
        "\n",
        "# # Lấy thông tin collection\n",
        "# collection_info = client.get_collection(\"nttu_sotay_vector_db_v1\")\n",
        "# print(\"Collection info:\", collection_info)\n",
        "\n",
        "# # Lấy một số points để kiểm tra\n",
        "# points = client.scroll(\n",
        "#     collection_name=\"nttu_sotay_vector_db_v1\",\n",
        "#     limit=2  # Lấy 2 điểm đầu tiên\n",
        "# )\n",
        "# for point in points[0]:\n",
        "#     print(\"\\nPoint ID:\", point.id)\n",
        "#     print(\"Payload:\", point.payload)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Gr53v7v1wBnQ"
      },
      "outputs": [],
      "source": [
        "# # Truy vấn\n",
        "# query = \"Xếp loại học bổng ở trường\"\n",
        "\n",
        "# # Chuyển đổi truy vấn thành vector\n",
        "# query_vector = embeddings.embed_query(query)\n",
        "\n",
        "# # Tìm kiếm trong collection\n",
        "# search_results = client.search(\n",
        "#     collection_name=\"nttu_sotay_vector_db_v1\",\n",
        "#     query_vector=query_vector,\n",
        "#     limit=5  # Số lượng kết quả muốn lấy\n",
        "# )\n",
        "\n",
        "# # In kết quả\n",
        "# for result in search_results:\n",
        "#     print(\"\\nPoint ID:\", result.id)\n",
        "#     print(\"Score:\", result.score)  # Điểm số tương tự\n",
        "#     print(\"Payload:\", result.payload)  # Nội dung và metadata"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b3d790938334583b70b65de8fda3146": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c340060d6584cf385abe111e21e862e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa5fa77e38bf48049044f0a6ff8d8fe4",
              "IPY_MODEL_819ad45e1b6e4c4a90a7d0da937df31f",
              "IPY_MODEL_8e43c12757d34f95953cce24bc3f3290"
            ],
            "layout": "IPY_MODEL_829c1b9b5d2e4dbc9a5abca314599002"
          }
        },
        "30cffb5f9d1946a190c818227a412cf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b06f357194c4fc699956b868bf1d374": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79d84040ae8245578a5d3e8719610e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "819ad45e1b6e4c4a90a7d0da937df31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db4d9fd4dfcb4eaa8c6dad909e9ae305",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ddf11837ebb941b1a3c9de221b225ef9",
            "value": 1
          }
        },
        "829c1b9b5d2e4dbc9a5abca314599002": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e43c12757d34f95953cce24bc3f3290": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b3d790938334583b70b65de8fda3146",
            "placeholder": "​",
            "style": "IPY_MODEL_30cffb5f9d1946a190c818227a412cf9",
            "value": "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:29&lt;00:00, 29.80s/it]\n"
          }
        },
        "db4d9fd4dfcb4eaa8c6dad909e9ae305": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddf11837ebb941b1a3c9de221b225ef9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fa5fa77e38bf48049044f0a6ff8d8fe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b06f357194c4fc699956b868bf1d374",
            "placeholder": "​",
            "style": "IPY_MODEL_79d84040ae8245578a5d3e8719610e7e",
            "value": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
