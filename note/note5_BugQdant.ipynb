{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "\n",
    "#  INFO:     2405:4802:182d:20c0:4480:65c0:d6dd:cac4:0 - \"GET /rag/nttu?q=xin%20ch%C3%A0o HTTP/1.1\" 500 Internal Server Error\n",
    "# <ipython-input-7-d0ef9f03339d>:38: LangChainDeprecationWarning: The class `Qdrant` was deprecated in LangChain 0.0.37 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-qdrant package and should be used instead. To use it run `pip install -U :class:`~langchain-qdrant` and import as `from :class:`~langchain_qdrant import Qdrant``.\n",
    "#   db = Qdrant(client=client,\n",
    "# <ipython-input-15-a883cb622b5a>:42: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
    "#   data = app.rag(source=source)(q)\n",
    "```\n",
    "\n",
    "```python\n",
    "    try:\n",
    "        # Thực hiện truy vấn RAG\n",
    "        # data = app.rag(source=source)(q)\n",
    "        data = app.rag(source=source).invoke(q)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Test endpoint root**:\n",
    "```bash\n",
    "curl https://briefly-knowing-treefrog.ngrok-free.app/\n",
    "```\n",
    "=> oke\n",
    "2. **Test endpoint RAG với source \"nttu\"**:\n",
    "```bash\n",
    "curl \"https://briefly-knowing-treefrog.ngrok-free.app/rag/nttu?q=xin%20chao\"\n",
    "```\n",
    "=> bug\n",
    "\n",
    "\n",
    "```\n",
    "{\n",
    "    \"detail\": \"An error occurred: 'VectorStoreRetriever' object has no attribute 'embeddings'\"\n",
    "}\n",
    "\n",
    "Là lỗi gì \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Có, trong code của bạn đã tạo embeddings. Hãy phân tích từng phần:\n",
    "\n",
    "1. **Tạo embeddings model**:\n",
    "```python\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    api_key = HUGGINGFACE_API_KEY,\n",
    "    model_kwargs = {'device': 'auto'}\n",
    ")\n",
    "```\n",
    "Đây là bước khởi tạo model embeddings sử dụng HuggingFace API.\n",
    "\n",
    "2. **Sử dụng embeddings để tạo vector database**:\n",
    "```python\n",
    "qdrant = Qdrant.from_documents(\n",
    "    texts_sotay,\n",
    "    embeddings,  # Embeddings model được sử dụng ở đây\n",
    "    url=QDRANT_URL,\n",
    "    prefer_grpc=False,\n",
    "    collection_name=\"nttu_sotay_vector_db_v1\",\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")\n",
    "```\n",
    "\n",
    "3. **Kiểm tra embeddings hoạt động**:\n",
    "```python\n",
    "# Test tìm văn bản liên quan đến query\n",
    "query = \"Xếp loại học bổng ở trường\"\n",
    "found_docs = qdrant.similarity_search(query,k=15)\n",
    "```\n",
    "Nếu `similarity_search` hoạt động, điều này xác nhận rằng:\n",
    "- Embeddings đã được tạo thành công\n",
    "- Dữ liệu đã được lưu trong Qdrant database\n",
    "- Quá trình tìm kiếm vector similarity đang hoạt động\n",
    "\n",
    "Để kiểm tra thêm, bạn có thể:\n",
    "```python\n",
    "# Kiểm tra xem embeddings có hoạt động không\n",
    "test_embedding = embeddings.embed_query(\"test query\")\n",
    "print(f\"Embedding dimension: {len(test_embedding)}\")\n",
    "```\n",
    "\n",
    "Nếu code trên chạy mà không có lỗi và trả về một vector có chiều dài hợp lý, thì embeddings đã được tạo và hoạt động đúng.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Có những phần nào lưu vào database??\n",
    "Những trường nào ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chưa hiểu lắm cách lưu Qdant trong code "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Hãy phân tích chi tiết cách dữ liệu được ghi vào Qdrant:\n",
    "\n",
    "1. **Quá trình xử lý văn bản**:\n",
    "```python\n",
    "# 1. Load văn bản từ file\n",
    "loader_sotay = TextLoader(\"sotay.txt\")\n",
    "documents_sotay = loader_sotay.load()\n",
    "\n",
    "# 2. Cắt văn bản thành các đoạn nhỏ\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=800,    # Mỗi đoạn dài 800 ký tự\n",
    "    chunk_overlap=400  # Overlap 400 ký tự để tránh mất ngữ cảnh\n",
    ")\n",
    "texts_sotay = text_splitter.split_documents(documents_sotay)\n",
    "```\n",
    "\n",
    "2. **Tạo embeddings**:\n",
    "```python\n",
    "# Khởi tạo model embeddings\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "    api_key = HUGGINGFACE_API_KEY,\n",
    "    model_kwargs = {'device': 'auto'}\n",
    ")\n",
    "```\n",
    "\n",
    "3. **Ghi vào Qdrant**:\n",
    "```python\n",
    "# Phương thức from_documents sẽ:\n",
    "qdrant = Qdrant.from_documents(\n",
    "    texts_sotay,      # List các document đã cắt nhỏ\n",
    "    embeddings,       # Model để chuyển text thành vector\n",
    "    url=QDRANT_URL,   # URL của Qdrant server\n",
    "    collection_name=\"nttu_sotay_vector_db_v1\",  # Tên collection\n",
    "    api_key=QDRANT_API_KEY,\n",
    ")\n",
    "```\n",
    "\n",
    "4. **Chi tiết quá trình ghi**:\n",
    "```python\n",
    "# Bên trong from_documents, quá trình diễn ra như sau:\n",
    "for doc in texts_sotay:\n",
    "    # 1. Tạo vector từ nội dung văn bản\n",
    "    vector = embeddings.embed_query(doc.page_content)\n",
    "    \n",
    "    # 2. Tạo payload (metadata)\n",
    "    payload = {\n",
    "        \"page_content\": doc.page_content,\n",
    "        \"metadata\": doc.metadata\n",
    "    }\n",
    "    \n",
    "    # 3. Ghi vào Qdrant\n",
    "    # - Vector được lưu để tìm kiếm similarity\n",
    "    # - Payload được lưu kèm để trả về kết quả\n",
    "```\n",
    "\n",
    "5. **Kiểm tra dữ liệu đã lưu**:\n",
    "```python\n",
    "from qdrant_client import QdrantClient\n",
    "\n",
    "# Kết nối tới Qdrant\n",
    "client = QdrantClient(url=QDRANT_URL, api_key=QDRANT_API_KEY)\n",
    "\n",
    "# Lấy thông tin collection\n",
    "collection_info = client.get_collection(\"nttu_sotay_vector_db_v1\")\n",
    "print(\"Collection info:\", collection_info)\n",
    "\n",
    "# Lấy một số points để kiểm tra\n",
    "points = client.scroll(\n",
    "    collection_name=\"nttu_sotay_vector_db_v1\",\n",
    "    limit=2  # Lấy 2 điểm đầu tiên\n",
    ")\n",
    "for point in points[0]:\n",
    "    print(\"\\nPoint ID:\", point.id)\n",
    "    print(\"Payload:\", point.payload)\n",
    "```\n",
    "\n",
    "Khi tìm kiếm:\n",
    "```python\n",
    "# Khi bạn search:\n",
    "query = \"Xếp loại học bổng ở trường\"\n",
    "found_docs = qdrant.similarity_search(query, k=15)\n",
    "\n",
    "# Quá trình xảy ra:\n",
    "# 1. Query được chuyển thành vector\n",
    "# 2. Tìm k vectors gần nhất trong database\n",
    "# 3. Trả về documents tương ứng với các vectors đó\n",
    "```\n",
    "\n",
    "Bạn có muốn tôi giải thích thêm phần nào không?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QUAY LẠI BUG \n",
    "```\n",
    "curl --location 'https://briefly-knowing-treefrog.ngrok-free.app/rag/nttu?q=xin%20chao'\n",
    "\n",
    "{\n",
    "    \"detail\": \"An error occurred: 'VectorStoreRetriever' object has no attribute 'embeddings'\"\n",
    "}\n",
    "\n",
    "bug này là sao\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lỗi `\"An error occurred: 'VectorStoreRetriever' object has no attribute 'embeddings'\"` cho thấy rằng trong mã của bạn, một đối tượng thuộc lớp `VectorStoreRetriever` đang cố gắng truy cập thuộc tính `embeddings`, nhưng thuộc tính này không tồn tại.\n",
    "\n",
    "### Nguyên nhân và Giải pháp\n",
    "\n",
    "1. **Kiểm tra Class `RerankRetriever`**:\n",
    "   - Đảm bảo rằng bạn đã định nghĩa thuộc tính `embeddings` trong class `RerankRetriever`. Nếu không, bạn cần thêm nó.\n",
    "\n",
    "   ```python\n",
    "   class RerankRetriever(VectorStoreRetriever):\n",
    "       vectorstore: VectorStoreRetriever\n",
    "\n",
    "       @property\n",
    "       def embeddings(self):\n",
    "           return self.vectorstore.embeddings  # Đảm bảo vectorstore có embeddings\n",
    "   ```\n",
    "\n",
    "2. **Kiểm tra Khởi tạo `vectorstore`**:\n",
    "   - Đảm bảo rằng `vectorstore` được khởi tạo với một đối tượng có thuộc tính `embeddings`. Nếu bạn đang sử dụng Qdrant, hãy chắc chắn rằng bạn đã khởi tạo đúng cách.\n",
    "\n",
    "3. **Cập nhật `from_documents`**:\n",
    "   - Nếu bạn đã cập nhật `langchain`, hãy kiểm tra xem có thay đổi nào trong cách khởi tạo `VectorStoreRetriever` không.\n",
    "\n",
    "4. **Kiểm tra Mã Gọi API**:\n",
    "   - Đảm bảo rằng mã gọi API đang sử dụng đúng class và không có lỗi trong quá trình khởi tạo.\n",
    "\n",
    "### Ví dụ Cụ Thể\n",
    "\n",
    "Dưới đây là một ví dụ về cách bạn có thể định nghĩa class `RerankRetriever`:\n",
    "\n",
    "```python\n",
    "class RerankRetriever(VectorStoreRetriever):\n",
    "    vectorstore: VectorStoreRetriever\n",
    "\n",
    "    @property\n",
    "    def embeddings(self):\n",
    "        return self.vectorstore.embeddings  # Đảm bảo vectorstore có embeddings\n",
    "\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        docs = self.vectorstore.get_relevant_documents(query=query)\n",
    "        candidates = [doc.page_content for doc in docs]\n",
    "        queries = [query] * len(candidates)\n",
    "        features = tokenizer_rerank(queries, candidates, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            scores = model_rerank(**features).logits\n",
    "            values, indices = torch.sum(scores, dim=1).sort()\n",
    "        return [docs[indices[0]], docs[indices[1]]]\n",
    "```\n",
    "\n",
    "### Kiểm Tra\n",
    "\n",
    "- Sau khi thực hiện các thay đổi, hãy thử lại yêu cầu curl và xem lỗi có còn không.\n",
    "- Nếu vẫn gặp lỗi, hãy kiểm tra log chi tiết của backend để biết thêm thông tin về nguyên nhân.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from langchain.schema.document import Document\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "from typing import List\n",
    "class RerankRetriever(VectorStoreRetriever):\n",
    "    vectorstore: VectorStoreRetriever\n",
    "    @property\n",
    "    def embeddings(self):\n",
    "        return self.vectorstore.embeddings  # Đảm bảo vectorstore có embeddings\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        docs = self.vectorstore.get_relevant_documents(query=query)\n",
    "        candidates = [doc.page_content for doc in docs]\n",
    "        queries = [query]*len(candidates)\n",
    "        features = tokenizer_rerank(queries, candidates,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            scores = model_rerank(**features).logits\n",
    "            values, indices = torch.sum(scores, dim=1).sort()\n",
    "            # relevant_docs = docs[indices[0]]\n",
    "        return [docs[indices[0]],docs[indices[1]]]\n",
    "class RerankWikiRetriever(VectorStoreRetriever):\n",
    "    vectorstore: WikipediaRetriever\n",
    "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
    "        docs = self.vectorstore.get_relevant_documents(query=query)\n",
    "        candidates = [doc.page_content for doc in docs]\n",
    "        queries = [query]*len(candidates)\n",
    "        features = tokenizer_rerank(queries, candidates,  padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            scores = model_rerank(**features).logits\n",
    "            values, indices = torch.sum(scores, dim=1).sort()\n",
    "            # relevant_docs = docs[indices[0]]\n",
    "        return [docs[indices[0]],docs[indices[1]]]\n",
    "```\n",
    "<ipython-input-29-e5a01d4977d7>:5: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
    "  class RerankRetriever(VectorStoreRetriever):\n",
    "<ipython-input-29-e5a01d4977d7>:20: DeprecationWarning: Retrievers must implement abstract `_get_relevant_documents` method instead of `get_relevant_documents`\n",
    "  class RerankWikiRetriever(VectorStoreRetriever):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Cảnh báo `DeprecationWarning` cho biết rằng các lớp `RerankRetriever` và `RerankWikiRetriever` của bạn cần phải triển khai phương thức `_get_relevant_documents` thay vì `get_relevant_documents`. Điều này có nghĩa là API của `langchain` đã thay đổi và bạn cần cập nhật mã của mình để phù hợp với các thay đổi này.\n",
    "\n",
    "### Cách Sửa\n",
    "\n",
    "1. **Thay đổi tên phương thức**:\n",
    "   - Thay thế `get_relevant_documents` bằng `_get_relevant_documents`.\n",
    "\n",
    "2. **Cập nhật mã**:\n",
    "   Dưới đây là cách sửa mã của bạn:\n",
    "\n",
    "```python\n",
    "from langchain.schema.document import Document\n",
    "from langchain_core.vectorstores import VectorStoreRetriever\n",
    "from langchain.retrievers import WikipediaRetriever\n",
    "from typing import List\n",
    "\n",
    "class RerankRetriever(VectorStoreRetriever):\n",
    "    vectorstore: VectorStoreRetriever\n",
    "\n",
    "    @property\n",
    "    def embeddings(self):\n",
    "        return self.vectorstore.embeddings  # Đảm bảo vectorstore có embeddings\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:  # Thay đổi ở đây\n",
    "        docs = self.vectorstore.get_relevant_documents(query=query)\n",
    "        candidates = [doc.page_content for doc in docs]\n",
    "        queries = [query] * len(candidates)\n",
    "        features = tokenizer_rerank(queries, candidates, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            scores = model_rerank(**features).logits\n",
    "            values, indices = torch.sum(scores, dim=1).sort()\n",
    "        return [docs[indices[0]], docs[indices[1]]]\n",
    "\n",
    "class RerankWikiRetriever(VectorStoreRetriever):\n",
    "    vectorstore: WikipediaRetriever\n",
    "\n",
    "    def _get_relevant_documents(self, query: str) -> List[Document]:  # Thay đổi ở đây\n",
    "        docs = self.vectorstore.get_relevant_documents(query=query)\n",
    "        candidates = [doc.page_content for doc in docs]\n",
    "        queries = [query] * len(candidates)\n",
    "        features = tokenizer_rerank(queries, candidates, padding=True, truncation=True, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            scores = model_rerank(**features).logits\n",
    "            values, indices = torch.sum(scores, dim=1).sort()\n",
    "        return [docs[indices[0]], docs[indices[1]]]\n",
    "```\n",
    "\n",
    "### Giải thích\n",
    "- **Phương thức `_get_relevant_documents`**: Đây là phương thức mới mà bạn cần triển khai để thay thế cho `get_relevant_documents`. Điều này giúp đảm bảo rằng mã của bạn tương thích với phiên bản mới của `langchain`.\n",
    "\n",
    "### Kiểm tra lại\n",
    "Sau khi thực hiện các thay đổi này, hãy chạy lại mã của bạn và kiểm tra xem cảnh báo có còn không. Nếu bạn gặp phải lỗi khác, hãy cho tôi biết để tôi có thể hỗ trợ thêm!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sau khi thực hiện kiểm tra các kiểu: thư viện cũ nên ko nhận được embedding cần update code, .. => Mình phát hiện ra bug có thể ở data: check data thì thấy: DATASET content bị LƯU CHUNKING SAI SAI. \n",
    "\n",
    "\n",
    "```\n",
    "page_content\n",
    "a=this.i.length,b=this.i,c=[],d=0;d<a;++d){var e=b[d].i(),f=this.resolve(e);if(f&&f!=this.j[e])try{b[d].tb(f)}catch(g){}else c.push(b[d])}this.i=c.concat(b.slice(a))};var Dd=function(a){_.T.call(this);this.o=a;this.A=this.i=null;this.v=0;this.B={};this.j=!1;a=window.navigator.userAgent;a.indexOf(\"MSIE\")>=0&&a.indexOf(\"Trident\")>=0&&(a=/\\b(?:MSIE|rv)[: ]([^\\);]+)(\\)|;)/.exec(a))&&a[1]&&parseFloat(a[1])<9&&(this.j=!0)};_.A(Dd,_.T);Dd.prototype.C=function(a,b){this.i=b;this.A=a;b.preventDefault?b.preventDefault():b.returnValue=!1};_.Ed=function(a){this.J=_.w(a)};_.A(_.Ed,_.S);var Fd=function(a){this.J=_.w(a)};_.A(Fd,_.S);var Hd=function(){var a=Gd;this.i=null;_.M(a,4,!0)};Hd.prototype.log=function(a,b,c){c=c===void 0?new _.zd:c;_.Id(this,a,98,c)};_.Id=function(a,b,c,d){c=c===void\n",
    "metadata\n",
    "{\n",
    "\"source\":\"Luat.txt\"\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sau khi tiến hành chunking lại thì phát hiện thêm: ??? bug ở CHUNKING: mãi do TOKEN HUGGINGFACE của ông kia sai => FIX xong cái thì database lên Qdant và work ngon"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
